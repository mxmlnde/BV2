{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "lf7Ciw1ILUJM"
      },
      "outputs": [],
      "source": [
        "from torch.utils.data import Dataset, DataLoader\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "from torchvision import datasets\n",
        "from torch.optim import SGD\n",
        "from timeit import default_timer as timer\n",
        "\n",
        "device = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
        "print( f\"device: {device}\" )\n",
        "\n",
        "\n",
        "# Umschalten zwischen Colab oder lokaler Installation\n",
        "USING_COLAB = True\n",
        "\n",
        "if USING_COLAB:\n",
        "  from google.colab import drive\n",
        "  from google.colab.patches import cv2_imshow\n",
        "  drive.mount('/content/drive')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "vQXCN16HLUJR"
      },
      "source": [
        "Download and load the training data"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "QRFb8iwnLUJU"
      },
      "outputs": [],
      "source": [
        "train_set = datasets.MNIST('data/', download=True, train=True)\n",
        "train_images = train_set.data\n",
        "train_targets = train_set.targets"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "GnVk1LThLUJV"
      },
      "outputs": [],
      "source": [
        "test_set = datasets.MNIST('data/', download=True, train=False)\n",
        "test_images = test_set.data\n",
        "test_targets = test_set.targets"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "8rolrYZBLUJW"
      },
      "outputs": [],
      "source": [
        "class MNISTDataset(Dataset):\n",
        "    def __init__(self, x, y):\n",
        "        x = x.float()/255\n",
        "        x = x.view(-1,28*28)\n",
        "        self.x, self.y = x, y\n",
        "    def __getitem__(self, ix):\n",
        "        x, y = self.x[ix], self.y[ix]\n",
        "        return x.to(device), y.to(device)\n",
        "    def __len__(self):\n",
        "        return len(self.x)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Bp6nmcGfLUJW"
      },
      "outputs": [],
      "source": [
        "def get_data():\n",
        "    train = MNISTDataset(train_images, train_targets)\n",
        "    train_dl = DataLoader(train, batch_size=32, shuffle=True)\n",
        "    test = MNISTDataset(test_images, test_targets)\n",
        "    test_dl = DataLoader(test, batch_size=len(test_images), shuffle=True)\n",
        "    return train_dl, test_dl"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "9dCqz5klinHn"
      },
      "source": [
        "Modell (KNN) definieren mit beliebig vielen Schichten, die jeweils variable Anzahl Neuronen beinhalten. Wir beginnen hier immer mit 28x28 Eingabe-Neuronen und müssen am Ende immer auf 10 Ausgabe-Neuronen kommen"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ynAnfCnvLUJX"
      },
      "outputs": [],
      "source": [
        "def get_model():\n",
        "  model = nn.Sequential(\n",
        "    nn.Linear(28 * 28, 30),\n",
        "    nn.Tanh(),\n",
        "    nn.Linear(30, 20),\n",
        "    nn.Tanh(),\n",
        "    nn.Linear(20, 10)\n",
        "    ).to(device)\n",
        "  loss_fn = nn.CrossEntropyLoss()\n",
        "  optimizer = SGD(model.parameters(), lr=1e-2)\n",
        "  return model, loss_fn, optimizer"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "xxyRBE2qYL45"
      },
      "outputs": [],
      "source": [
        "def init_weights(m):\n",
        "  if type(m) == nn.Linear:\n",
        "    #m.weight.data.fill_(1)\n",
        "    #m.weight.data.uniform_(-0.1, 0.1)\n",
        "    m.weight.data.normal_(0.0, 0.1)\n",
        "    if m.bias is not None:\n",
        "      m.bias.data.fill_(0)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "DDA7bVhtLUJY"
      },
      "outputs": [],
      "source": [
        "def train_batch(x, y, model, opt, loss_fn):\n",
        "  model.train()\n",
        "  prediction = model(x)\n",
        "  batch_loss = loss_fn(prediction, y)\n",
        "  batch_loss.backward()\n",
        "  optimizer.step()\n",
        "  optimizer.zero_grad()\n",
        "  return batch_loss.item()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "WQ2KVHOOLUJZ"
      },
      "outputs": [],
      "source": [
        "def accuracy(x, y, model):\n",
        "  model.eval()\n",
        "  with torch.no_grad():\n",
        "    prediction = model(x)\n",
        "  max_values, argmaxes = prediction.max(-1)\n",
        "  is_correct = argmaxes == y\n",
        "  return is_correct.cpu().numpy().tolist()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "y5Efay_nLUJa"
      },
      "outputs": [],
      "source": [
        "def loss(x, y, model, loss_fn):\n",
        "  model.eval()\n",
        "  with torch.no_grad():\n",
        "    prediction = model(x)\n",
        "    loss = loss_fn(prediction, y)\n",
        "  return loss.item()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "bq_F7QVcLUJb"
      },
      "outputs": [],
      "source": [
        "train_dl, test_dl = get_data()\n",
        "model, loss_fn, optimizer = get_model()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "1sOWl018LUJc"
      },
      "outputs": [],
      "source": [
        "#----------------------------------------------\n",
        "# Training >>>\n",
        "#\n",
        "print('Starting training...')\n",
        "\n",
        "model.apply(init_weights)  # hier werden die initialen Gewichte des Netzes zufällig gesetzt\n",
        "\n",
        "epochs = 50\n",
        "\n",
        "arrPlotX = []\n",
        "train_losses, train_accuracies = [], []\n",
        "test_losses, test_accuracies = [], []\n",
        "for epoch in range(epochs):\n",
        "  timeBeginEpoch = timer()\n",
        "  train_epoch_losses, train_epoch_accuracies = [], []\n",
        "\n",
        "  for ix, batch in enumerate(iter(train_dl)):\n",
        "    x, y = batch\n",
        "    batch_loss = train_batch(x, y, model, optimizer, loss_fn)\n",
        "    train_epoch_losses.append(batch_loss)\n",
        "    is_correct = accuracy(x, y, model)\n",
        "    train_epoch_accuracies.extend(is_correct)\n",
        "\n",
        "  train_epoch_loss = np.array(train_epoch_losses).mean()\n",
        "  train_epoch_accuracy = np.mean(train_epoch_accuracies)\n",
        "\n",
        "  for ix, batch in enumerate(iter(test_dl)):\n",
        "    x, y = batch\n",
        "    val_is_correct = accuracy(x, y, model)\n",
        "    validation_loss = loss(x, y, model, loss_fn)\n",
        "\n",
        "  val_epoch_accuracy = np.mean(val_is_correct)\n",
        "  arrPlotX.append(epoch)\n",
        "  train_losses.append(train_epoch_loss)\n",
        "  train_accuracies.append(train_epoch_accuracy)\n",
        "  test_losses.append(validation_loss)\n",
        "  test_accuracies.append(val_epoch_accuracy)\n",
        "  timeEndEpoch = timer()\n",
        "  print( f\"epoch: {epoch}  train_acc: {100 * train_epoch_accuracy:.2f}%  test_acc: {100 * val_epoch_accuracy:.2f}%  took {timeEndEpoch-timeBeginEpoch:.1f}s\" )"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "JuZmxWzqLUJe"
      },
      "outputs": [],
      "source": [
        "if USING_COLAB:\n",
        "  torch.save(model.state_dict(), '/content/drive/My Drive/Colab Notebooks/BV2/results/nnMnist_exp01.pt')\n",
        "else:\n",
        "  torch.save(model.state_dict(), 'nnMnist_exp01.pt')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ZDkUvtl_LUJe"
      },
      "outputs": [],
      "source": [
        "plt.plot(arrPlotX, train_accuracies)\n",
        "plt.plot(arrPlotX, test_accuracies)\n",
        "\n",
        "if USING_COLAB:\n",
        "  plt.savefig('/content/drive/My Drive/Colab Notebooks/BV2/results/accuracies_exp0.png')\n",
        "else:\n",
        "  plt.savefig('accuracies_exp0.png')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "FR9XI_13y-0D"
      },
      "outputs": [],
      "source": [
        "plt.plot(arrPlotX, train_losses)\n",
        "plt.plot(arrPlotX, test_losses)\n",
        "\n",
        "if USING_COLAB:\n",
        "  plt.savefig('/content/drive/My Drive/Colab Notebooks/BV2/results/losses_exp0.png')\n",
        "else:\n",
        "  plt.savefig('losses_exp0.png')"
      ]
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "provenance": []
    },
    "gpuClass": "standard",
    "kernelspec": {
      "display_name": "Python 3 (ipykernel)",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.7.9"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}